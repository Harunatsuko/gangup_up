{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport pandas as pd\nimport os\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport matplotlib.pyplot as plt\n\n\nfrom keras.models import Model\nfrom keras.models import model_from_json\nfrom keras.models import load_model\n# from keras.preprocessing import image\nimport keras.utils as image\n# from keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.imagenet_utils import preprocess_input, decode_predictions\n\nfrom scipy import spatial\n\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-27T21:57:10.447242Z","iopub.execute_input":"2023-10-27T21:57:10.448823Z","iopub.status.idle":"2023-10-27T21:57:10.456463Z","shell.execute_reply.started":"2023-10-27T21:57:10.448775Z","shell.execute_reply":"2023-10-27T21:57:10.455446Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/video0/frame0/'","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:23:40.943495Z","iopub.execute_input":"2023-10-27T21:23:40.944066Z","iopub.status.idle":"2023-10-27T21:23:40.948823Z","shell.execute_reply.started":"2023-10-27T21:23:40.944028Z","shell.execute_reply":"2023-10-27T21:23:40.947662Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(os.path.join(path, 'video0_labels.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:28:01.220781Z","iopub.execute_input":"2023-10-27T21:28:01.221246Z","iopub.status.idle":"2023-10-27T21:28:01.233942Z","shell.execute_reply.started":"2023-10-27T21:28:01.221208Z","shell.execute_reply":"2023-10-27T21:28:01.232208Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df = data[data['frame_number']==0]\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:28:13.093798Z","iopub.execute_input":"2023-10-27T21:28:13.095093Z","iopub.status.idle":"2023-10-27T21:28:13.107217Z","shell.execute_reply.started":"2023-10-27T21:28:13.095032Z","shell.execute_reply":"2023-10-27T21:28:13.106429Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   frame_number  object_id  label       x       y       w       h\n0             0          8      0  0.4906  0.3667  0.3188  0.7278\n1             0         23      2  0.1016  0.2250  0.1250  0.4444\n2             0         28      2  0.0430  0.4972  0.0859  0.3278","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame_number</th>\n      <th>object_id</th>\n      <th>label</th>\n      <th>x</th>\n      <th>y</th>\n      <th>w</th>\n      <th>h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.4906</td>\n      <td>0.3667</td>\n      <td>0.3188</td>\n      <td>0.7278</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>23</td>\n      <td>2</td>\n      <td>0.1016</td>\n      <td>0.2250</td>\n      <td>0.1250</td>\n      <td>0.4444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>28</td>\n      <td>2</td>\n      <td>0.0430</td>\n      <td>0.4972</td>\n      <td>0.0859</td>\n      <td>0.3278</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def load_model(model_name, include_top=True):\n    \"\"\" Load pre-trained Keras model\n    Args:\n        model_name: String, name of model to load\n        include_top: String, the model is buildt with 'feature learning block' + 'classification block'\n    Returns:\n        model: Keras model instance\n    \"\"\"\n    if selected_model in available_models:\n        # Load a Keras instance\n        try:\n            if model_name == 'vgg16':\n                model = VGG16(weights='imagenet', include_top=include_top)\n            elif model_name == 'resnet50':\n                model = ResNet50(weights='imagenet', include_top=include_top)\n            print(f\">> '{model.name}' model successfully loaded!\")\n        except:\n            print(f\">> Error while loading model '{selected_model}'\")\n    \n    # Wrong selected model\n    else:\n        print(f\">> Error: there is no '{selected_model}' in {available_models}\")\n    \n    return model\n\n\ndef get_img_size_model(model):\n    \"\"\"Returns image size for image processing to be used in the model\n    Args:\n        model: Keras model instance \n    Returns:\n        img_size_model: Tuple of integers, image size\n    \"\"\"\n    model_name = model.name\n    if model_name == \"vgg16\":\n        img_size_model = (224, 224)\n    elif model_name == \"resnet50\":\n        img_size_model = (224, 224)\n    else:\n        img_size_model = (224, 224)\n        print(\"Warning: model name unknown. Default image size: {}\".format(img_size_model))\n        \n    return img_size_model\n\n\ndef image_processing(img_array):\n    \"\"\" Preprocess image to be used in a keras model instance\n    Args:\n        img_array: Numpy array of an image which will be predicte\n    Returns:\n        processed_img = Numpy array which represents the processed image\n    \"\"\"    \n    # Expand the shape\n    img = np.expand_dims(img_array, axis=0)\n\n    # Convert image from RGB to BGR (each color channel is zero-centered with respect to the ImageNet dataset, without scaling)\n    processed_img = preprocess_input(img)\n    \n    return processed_img\n\n\n\ndef get_layername_feature_extraction(model):\n    \"\"\" Return the name of last layer for feature extraction   \n    Args:\n        model: Keras model instance\n    Returns:\n        layername_feature_extraction: String, name of the layer for feature extraction\n    \"\"\"\n    model_name = model.name\n    if model_name == \"vgg16\":\n        layername_feature_extraction = 'fc2'\n    elif model_name == \"resnet50\":\n        layername_feature_extraction = 'predictions'\n    else:\n        layername_feature_extraction = ''\n        print(\"Warning: model name unknown. Default layername: '{}'\".format(layername_feature_extraction))\n    \n    return layername_feature_extraction\n\n\ndef get_feature_vector(model, img_path):\n    \"\"\" Get a feature vector extraction from an image by using a keras model instance\n    Args:\n        model: Keras model instance used to do the classification.\n        img_path: String to the image path which will be predicted\n    Returns:\n        feature_vect: List of visual feature from the input image\n    \"\"\"\n    \n    # Creation of a new keras model instance without the last layer\n    layername_feature_extraction = get_layername_feature_extraction(model)\n    model_feature_vect = Model(inputs=model.input, outputs=model.get_layer(layername_feature_extraction).output)\n    \n    # Image processing\n    img_size_model = get_img_size_model(model)\n    img = image.load_img(img_path, target_size=img_size_model)\n    img_arr = np.array(img)\n    img_ = image_processing(img_arr)\n    \n    # Visual feature extraction\n    feature_vect = model_feature_vect.predict(img_)\n    \n    return feature_vect\n\n\n\ndef calculate_similarity(vector1, vector2):\n    \"\"\"Compute similarities between two images using 'cosine similarities'\n    Args:\n        vector1: Numpy vector to represent feature extracted vector from image 1\n        vector2: Numpy vector to represent feature extracted vector from image 1\n    Returns:\n        sim_cos: Float to describe the similarity between both images\n    \"\"\"\n    sim_cos = 1-spatial.distance.cosine(vector1, vector2)\n    \n    return sim_cos\n\n\n\ndef compute_similarity_img(model, img_path_1, img_path_2):\n    \"\"\" Return a cosine similarity between both images and display them in HTML\n    Args:\n        model: Keras model instance used to do the feature extraction\n        img_path_1: String to the image 1 path\n        img_path_2: String to the image 2 path\n    Returns:\n        sim_cos: Float to describe the similarity between both images\n    \"\"\"\n    filename1 = os.path.basename(img_path_1).split(\".\")[0]\n    filename2 = os.path.basename(img_path_2).split(\".\")[0]\n    \n    # Compute feature vector extracted\n    fea_vec_img1 = get_feature_vector(model, img_path_1)\n    fea_vec_img2 = get_feature_vector(model, img_path_2)\n    \n    # Compute cosine similarity\n    sim_cos = calculate_similarity(fea_vec_img1, fea_vec_img2)\n    \n    # Read images\n    img_size_model = get_img_size_model(model)\n    im1 = cv2.resize(cv2.imread(img_path_1), dsize=img_size_model, interpolation = cv2.INTER_AREA)\n    im2 = cv2.resize(cv2.imread(img_path_2), dsize=img_size_model, interpolation = cv2.INTER_AREA)\n    \n    # Concatenate images horizontally\n    im12 = cv2.hconcat([im1, im2])\n    \n    # Save concatenated image\n    dst_dir_cos_sim = \"../report/cos_sim\"\n    create_folder(dst_dir_cos_sim)\n    dst_dir = f\"{dst_dir_cos_sim}/{model.name}\"\n    create_folder(dst_dir)\n    \n    new_filename = f\"{filename1}_{filename2}\"\n    cv2.imwrite(f\"{dst_dir}/{new_filename}.jpg\", im12)\n\n    # Display images with cosine similarity result with HTML\n    thumb = \"<div style='margin: 0px;'> ({}) {}/{}: cos_sim = {:.4f}</div>\".format(model.name, filename1, filename2, sim_cos)\n    thumb += ''.join( [\"<img style='width: 300px; margin: 0px; float: left; border: 1px solid black;' src='%s'/>\" %str(s)\n                       for s in sorted(glob('{}/{}.jpg'.format(dst_dir, new_filename))) ])\n    \n    display(HTML(thumb))\n    print()\n    \n    return sim_cos\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:56:40.058952Z","iopub.execute_input":"2023-10-27T21:56:40.059844Z","iopub.status.idle":"2023-10-27T21:56:40.077537Z","shell.execute_reply.started":"2023-10-27T21:56:40.059809Z","shell.execute_reply":"2023-10-27T21:56:40.075951Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"available_models = ['vgg16', 'resnet50']\nselected_model = 'resnet50'\n\nmodel = load_model(selected_model, include_top=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:56:40.695767Z","iopub.execute_input":"2023-10-27T21:56:40.696133Z","iopub.status.idle":"2023-10-27T21:56:42.536810Z","shell.execute_reply.started":"2023-10-27T21:56:40.696104Z","shell.execute_reply":"2023-10-27T21:56:42.535262Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":">> 'resnet50' model successfully loaded!\n","output_type":"stream"}]},{"cell_type":"code","source":"img1 = os.path.join(path, '8.jpg')\nimg2 = os.path.join(path, '213.jpg')\n\ncompute_similarity_img(model, img1, img2)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:57:15.629363Z","iopub.execute_input":"2023-10-27T21:57:15.629734Z","iopub.status.idle":"2023-10-27T21:57:18.277083Z","shell.execute_reply.started":"2023-10-27T21:57:15.629704Z","shell.execute_reply":"2023-10-27T21:57:18.275454Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 882ms/step\n1/1 [==============================] - 1s 846ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m img1 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m img2 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m213.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcompute_similarity_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[37], line 139\u001b[0m, in \u001b[0;36mcompute_similarity_img\u001b[0;34m(model, img_path_1, img_path_2)\u001b[0m\n\u001b[1;32m    136\u001b[0m fea_vec_img2 \u001b[38;5;241m=\u001b[39m get_feature_vector(model, img_path_2)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m sim_cos \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfea_vec_img1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfea_vec_img2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Read images\u001b[39;00m\n\u001b[1;32m    142\u001b[0m img_size_model \u001b[38;5;241m=\u001b[39m get_img_size_model(model)\n","Cell \u001b[0;32mIn[37], line 116\u001b[0m, in \u001b[0;36mcalculate_similarity\u001b[0;34m(vector1, vector2)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_similarity\u001b[39m(vector1, vector2):\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute similarities between two images using 'cosine similarities'\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m        vector1: Numpy vector to represent feature extracted vector from image 1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m        sim_cos: Float to describe the similarity between both images\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     sim_cos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[43mspatial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sim_cos\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/spatial/distance.py:684\u001b[0m, in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# clamp the result to 0-2\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;241m2.0\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/spatial/distance.py:624\u001b[0m, in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrelation\u001b[39m(u, v, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, centered\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    592\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    Compute the correlation distance between two 1-D arrays.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m     v \u001b[38;5;241m=\u001b[39m _validate_vector(v)\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/spatial/distance.py:318\u001b[0m, in \u001b[0;36m_validate_vector\u001b[0;34m(u, dtype)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput vector should be 1-D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Input vector should be 1-D."],"ename":"ValueError","evalue":"Input vector should be 1-D.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}